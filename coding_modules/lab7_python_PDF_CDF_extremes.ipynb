{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b290235-8f87-4608-ab0f-ce381395eed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165ccb20-61bc-40b6-8367-ad386f23ff90",
   "metadata": {},
   "source": [
    "# Python inclass practice 7: PDF, CDF, Extreme events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995bacd9-c29a-4dc8-aaaf-3f90f97eb456",
   "metadata": {
    "tags": []
   },
   "source": [
    "### In this practice, we will continue using the data from last lab\n",
    "Site id: 04216000 (Niagara River near Buffalo NY) </br>\n",
    "Site id: 04215000 (Cayuga Creek near Lancaster NY) </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78f9d00-b27e-4d10-95b4-4f382fc8cee4",
   "metadata": {},
   "source": [
    "## 0. Prep: read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d594d03-8036-4afc-b8f9-65e9d4b10002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just in case you did not get through the first section\n",
    "df_concat_sel = pd.read_csv(\"../data/python_inclass_practice_6.data.csv\",index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02411753-b0be-4c99-bf32-f1a38be585a8",
   "metadata": {},
   "source": [
    "# 1. PDF & CDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0248ef4e-6f95-42e4-ab6b-96dfbca46d78",
   "metadata": {},
   "source": [
    "## 1.1. Probability Density Function\n",
    "\n",
    "For discrete sample data, we usually use histogram `plt.hist` to visualize it. </br>\n",
    "Note: this plotting function has an option called `density`. If `density=False`, the plot will show the count falling within each bin. If `density=True`, the plot will show the probability density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18baa540-5291-4669-bab9-87598ba65818",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 1,figsize=[5,4],dpi=200)\n",
    "ax.hist(df_concat_sel['04216000'],bins=np.arange(100000,350000,10000),density=True)\n",
    "ax.set_title(\"PDF for streamflow in Niagara River\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c872134-2bd5-468e-b7e5-51c67ea64e00",
   "metadata": {},
   "source": [
    "### 1.1.1. It is important to choose bin size and scales wisely\n",
    "\n",
    "For example, the streamflow regime in Cayuga River is very spiky. Most of the time, the flow is between 0-100 cfs, but it also had some very high flow days with thousands cfs. Therefore, if we use normal scale plots with fixed bins, it will look like left plot below. However, if we use log-scale for x-axis with smart selection of bin width, the plot looks much better (like the one on the right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475903f5-6ebc-4b79-860c-6d68e9b55bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1, 2,figsize=[10,4],dpi=200)\n",
    "\n",
    "axes[0].hist(df_concat_sel['04215000'],bins=np.arange(100,4000,100),\n",
    "             density=True)\n",
    "axes[1].hist(df_concat_sel['04215000'],bins=np.concatenate([[0,1,2,5,10,20,50,80],\n",
    "                                                            np.arange(100,4000,100)]),\n",
    "             density=True)\n",
    "axes[1].set_xscale('log')\n",
    "axes[0].set_title(\"Linear-scale\")\n",
    "axes[1].set_title(\"Log-scale\")\n",
    "\n",
    "fig.suptitle(\"PDF for streamflow in Cayuga Creek\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8aeeaf-d2aa-4830-85c5-61f563cee11c",
   "metadata": {},
   "source": [
    "## 1.2. Cumulative Distribution Function\n",
    "\n",
    "If we have a discrete array of samples, and we would like to know the CDF of the sample, then we can just sort the array. If we look at the sorted result, we'll realize that the smallest value represents 0% , and largest value represents 100 %. Then all other arrays are assigned with evenly distributed probabilities between 0% and 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6530e73d-6f5b-4607-94b7-d440e9c41308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cumulative proportion of the data that falls below each value\n",
    "cumulative = np.linspace(0, 1, len(df_concat_sel['04216000']))\n",
    "\n",
    "# Sort the data in ascending order\n",
    "sorted_data = np.sort(df_concat_sel['04216000'])\n",
    "\n",
    "# Calculate the cumulative proportion of the sorted data\n",
    "cumulative_data = np.cumsum(sorted_data) / np.sum(sorted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450a8a75-67b4-4fb2-b040-eca3993ffed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the CDF\n",
    "plt.figure(dpi=300)\n",
    "plt.plot(sorted_data, cumulative_data, label='streamflow')\n",
    "plt.ylim(0,1)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Streamflow (cfs)\")\n",
    "plt.ylabel(\"Cumulative Proportion\")\n",
    "plt.title(\"Cumulative Distribution Function (CDF) of Mean daily flow\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9203b30-5770-45b3-9afb-58d3e7c14adb",
   "metadata": {},
   "source": [
    "## 1.2.1. Practice #1: plot CDF for Cayuga River. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2925ffa4-2f37-4acb-ba94-330c5887c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fc7cab-38bd-40e6-86cc-0656d37e584f",
   "metadata": {},
   "source": [
    "## 1.3. 100-year return floods\n",
    "\n",
    "As we discussed in class, to calculate the 100-year return floods, we can follow the three steps:\n",
    "1. Identify annual peak flow `groupby`\n",
    "2. Calculate the CDF for annual peak flow\n",
    "3. Calculate the Annual exceedance probability (AEP)\n",
    "4. In the AEP, find the flow value corresponds to AEP = 1%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4cd7d1-ae8b-499e-91ef-3358f88f110a",
   "metadata": {},
   "source": [
    "#### 1.3.1. Step 1: Identify annual peak flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f6b84-b183-49b5-8e8f-a454ac4a7d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify annual peak flow\n",
    "df_annual_max = df_concat_sel.groupby(df_concat_sel.index.year).max()\n",
    "df_annual_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1c9f12-05e4-45e6-93a1-6514f73e27c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.3.2. calculate cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa7e592-5359-437a-9135-c4e4d2cfd236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: calculate cdf\n",
    "# Calculate the cumulative proportion of the data that falls below each value\n",
    "cumulative_n = np.linspace(0, 1, len(df_annual_max['04216000']))\n",
    "\n",
    "# Sort the data in ascending order\n",
    "sorted_data_n = np.sort(df_annual_max['04216000'])\n",
    "\n",
    "# Calculate the cumulative proportion of the sorted data\n",
    "cumulative_data_n = np.cumsum(sorted_data_n) / np.sum(sorted_data_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7657dea5-60e9-4773-ad24-c81dc2d1e7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_data_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d42950-4b08-4271-a466-59bc3abc9e9b",
   "metadata": {},
   "source": [
    "#### 1.3.3. calculate AEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9084c15-d2a9-45cc-b6cc-4de335fab2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: calculate AEP\n",
    "aep_n = 1 - cumulative_data_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05079109-5ade-43f4-b822-37b9d908fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize AEP\n",
    "plt.figure(dpi=200)\n",
    "plt.plot(aep_n, sorted_data_n,  label='Niagara River Peak Flow')\n",
    "plt.scatter(aep_n, sorted_data_n)\n",
    "plt.axvline(0.01,lw=0.5,c='orange')\n",
    "plt.xlim(0,1)\n",
    "aep_list = np.array([0.01,0.05,0.1,0.2,0.5,1])\n",
    "aep_str = []\n",
    "for i in aep_list:\n",
    "    if i*100<1:\n",
    "        aep_str.append(\"%s%%\"%(i*100))\n",
    "    else:\n",
    "        aep_str.append(\"%i%%\"%(i*100))\n",
    "plt.xticks(aep_list,aep_str)\n",
    "plt.grid(lw=0.4)\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel(\"Streamflow (cfs)\")\n",
    "plt.xlabel(\"Annual Exceedance Probability\")\n",
    "plt.title(\"Annual Exceedance Probability\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fad5472-211c-4de3-91c6-6c5d33ceeed3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.3.4. find the flow corresponds to AEP = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df9917-44cd-4286-8cd6-1f30a17fab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4: find the flow corresponds to AEP = 0.01\n",
    "\n",
    "# Basically, we need to find the y value that \n",
    "# corresponds to the intersection of orange line \n",
    "# and blue dotted line above\n",
    "\n",
    "# asp_n[::-1] reverse this array, for example\n",
    "# a = [0,1,2], and a[::-1] will output [2,1,0]\n",
    "\n",
    "# The reason behind reverse the asp_n is\n",
    "# np.interp requires an monotonically increasing \n",
    "# sample points but our asp_n was in monotonically\n",
    "# decreasing order.\n",
    "\n",
    "flow_100yr_flood_n = np.interp(0.01, aep_n[::-1], sorted_data_n[::-1])\n",
    "print(\"The flood with 100-year recurrence interval is %.2f cfs\"%(flow_100yr_flood_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160ca38-aba3-437f-bd23-ea4c544da041",
   "metadata": {},
   "source": [
    "## 1.4.1. Practice #2: Please output the 100-year flood for Cayuga River"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2036167-61c5-4604-8347-d2ae2c311537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbb45d0-e021-488e-a1a3-e6bb71d2867e",
   "metadata": {},
   "source": [
    "## 1.5. 7Q10 for evaluating low flows!\n",
    "### 1.5.1. We first need to calculate the minimum annual 7-day average flow\n",
    "The syntax for rolling average is quite simple! </br>\n",
    "We can use `df.rolling()` to calculate the rolling average. </br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5205491f-0d38-4426-9a89-dd95bb683bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolling_7day_mean = df_concat_sel.rolling(7,center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038a66b-73a1-4a9d-aa66-69c0209d960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolling_7day_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e876924d-bd69-4114-9020-7448c2592aa4",
   "metadata": {},
   "source": [
    "# Note: the first three days and last three days does not have data!\n",
    "Because data was not available for the nearby 7-days at those dates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309332f7-0704-4754-826d-d581fea55cb0",
   "metadata": {},
   "source": [
    "### 1.5.2. Here we simply drop the NAN in the moving average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3756d36b-a4cb-4223-be61-e7c58c84028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rolling_7day_mean = df_rolling_7day_mean.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7b108d-38c5-4b8d-b43f-9df75b887e49",
   "metadata": {},
   "source": [
    "### 1.5.3. Practice #3: Can you calculate the 7Q10 for Niagara River?\n",
    "This is definitely a harder exercise! However, the philosophy behind the calculation is very similar to how we calculate the annual peak flow with 100-year recurrence interval.\n",
    "\n",
    "7Q10 is the 7-day average annual low flow with 10-year recurrence interval.\n",
    "\n",
    "1. Calculate the 7-day average flow (we have done in **1.5.1/1.5.2**)\n",
    "2. Find the annual minimum 7-day average flow (use groupby, see Section **1.3.1**)\n",
    "3. Calculate CDF, which equals to Annual Non-exceedance Probability (ANEP)!!\n",
    "4. Find the flow corresponds to ANEP = 0.1 (which corresponds to 10-year recurrence interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc970171-287c-4ace-813a-f9ba988a0310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify annual 7-day low flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b69e955-ae53-4fc9-98d4-10f04321bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: calculate cdf, which equals to anep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0abd4b-d1d9-4290-97f9-e2828c5c75c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 (optional): visualize ANEP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c046fd-829f-42fd-9862-430f510d044d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: find the flow corresponds to ANEP = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb4543c-86d9-4bc8-b824-fa05b966f65c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
